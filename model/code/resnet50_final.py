# -*- coding: utf-8 -*-
"""resnet50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FEHSzpcb_M40QnH5SOw8x2kLH_gaYeHr

# ***Importing Dataset from drive***
"""

# import drive
from google.colab import drive
drive.mount('/content/drive')

# code to unzip uploaded dataset folder
!unzip -uq "/content/drive/My Drive/Data.zip"

"""# ***Data*** ***Augmention***"""

from keras.preprocessing.image import ImageDataGenerator

# generating training dataset
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1. / 255)
valid_datagen= ImageDataGenerator(rescale=1. / 255)
train_data_dir="/content/Data/Train"
validation_data_dir="/content/Data/Valid"
img_height, img_width=224,224
batch_size=16

train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical')

nb_train_samples=6049

validation_generator = valid_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical')

test_generator = test_datagen.flow_from_directory(
    directory=r"/content/Data/Test",
    target_size=(224, 224),
    batch_size=1,
    class_mode=None,
    shuffle=False,
    seed=42
)

nb_validation_samples=1397
nb_test_samples=1863

"""# ***Applying Resnet Architecture on augmented images***"""

import tensorflow as tf
import keras.backend as K
from keras import regularizers
from keras.applications.resnet import ResNet50
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.applications.resnet50 import preprocess_input, decode_predictions
from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, CSVLogger
from keras.optimizers import SGD
from keras.regularizers import l2
from tensorflow import keras
import numpy as np

base_model=ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128,activation='relu')(x)
x = Dropout(0.2)(x)
predictions = Dense(9,kernel_regularizer=regularizers.l2(0.005),activation= 'softmax')(x)
model = Model(inputs = base_model.input, outputs = predictions)

# compile model
model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])
checkpointer = ModelCheckpoint(filepath='best_model_pretrain.hdf5', verbose=1, save_best_only=True)

# train model
history = model.fit_generator(train_generator,
                    steps_per_epoch = nb_train_samples //batch_size,
                    validation_data=validation_generator,
                    validation_steps= nb_validation_samples //batch_size,
                    epochs=20,
                    verbose=1,
                    callbacks=[checkpointer])

"""# **Matplotlib for displaying images and results**"""

import matplotlib.pyplot as plt
def plot_accuracy(history,title):
    plt.title(title)
    plt.plot(history.history['acc'])
    plt.plot(history.history['val_acc'])
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')
    plt.show()
def plot_loss(history,title):
    plt.title(title)
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train_loss', 'validation_loss'], loc='best')
    plt.show()

plot_accuracy(history,'FOOD')
plot_loss(history,'FOOD')

"""# ***Displaying Convolutional layers in resnet***"""

for layer in model.layers:
    print(layer.name)

validation_generator = valid_datagen.flow_from_directory(
    validation_data_dir,
    target_size=(img_height, img_width),
    batch_size=1,
    class_mode='categorical')

model.evaluate_generator(generator=validation_generator,
steps= nb_validation_samples //batch_size)

test_generator.reset()
pred=model.predict_generator(test_generator,
steps=test_generator.n//test_generator.batch_size,
verbose=1)

predicted_class_indices=np.argmax(pred,axis=1)
print(predicted_class_indices)

labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]

import pandas as pd
filenames=test_generator.filenames
results=pd.DataFrame({"Filename":filenames,
                      "Predictions":predictions})
results.to_csv("results.csv",index=False)

df=pd.read_csv('results.csv', delimiter = ',')
df

import numpy as np
cm=np.zeros((9,9))

from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
import os
label=['burger','burrito','club_sandwich','donuts','drink','french_fries','ice_cream','pizza','samosa']
length=[223,239,200,289,39,200,200,273,200]
j=-1
s=0
cnt=0
for i in length:
  s=s+i
  j=j+1
  if cnt >100:
        break
  for n in range(s-i,s):
    if (str(df["Predictions"][n])!=str(label[j])):
      img=str("/content/Data/Test/"+df["Filename"][n])
      img = image.load_img(img, target_size=(512, 512))
      img = image.img_to_array(img)                    
      img = np.expand_dims(img, axis=0)         
      img /= 255. 
      plt.imshow(img[0])
      plt.show()
      cnt+=1
      print("predicted ="+ str(df["Predictions"][n]))
      print("actual ="+ str(label[j]))
      if cnt >100:
        break

df.insert(2, "Actual", "Any")

df

cl=[]
j=0
prev=0
for i in length:
  prev+=i
  cl.append(prev)
j=0
for i in range(1863):
  if i>cl[j]:
    j+=1
  df["Actual"][i]=label[j]

df

y_true=[]
prev=0
k=-1
for i in cl:
  k+=1
  for j in range(prev,i):
    y_true.append(k)
  prev=i
print(y_true)
print(len(y_true))

pip install scikit-plot

"""# ***Code to display confusion matrix***"""

from sklearn.metrics import confusion_matrix
cm=(confusion_matrix(y_true, predicted_class_indices))
cmn=cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
cm=np.array(cm)
print(cm)

# displaying confusion matrix using seaborn
import seaborn as sns; sns.set()
import numpy as np; np.random.seed(0)
ax = sns.heatmap(cmn,center=1,linewidths=.5,xticklabels=label, yticklabels=label)

from sklearn.metrics import classification_report
print(classification_report(y_true, predicted_class_indices, target_names=label))

# Calorie Table
ctable=[295,206,220,300,41,312,207,266,262]

"""# ***Testing code for new and downloaded images***"""

from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
import os

def predict_class(model, images, show = True):
  for img in images:
    img = image.load_img(img, target_size=(224, 224))
    img = image.img_to_array(img)                    
    img = np.expand_dims(img, axis=0)         
    img /= 255.                                      
    pred = model.predict(img)
    index = np.argmax(pred)
    pred_value = label[index]
    if show:
        plt.imshow(img[0])                           
        plt.axis('off')
        plt.title(pred_value)
        plt.show()
        print("Calories " + str(ctable[index]))

"""# ***Code to load model***"""

import tensorflow.keras.backend as K
from tensorflow.keras.models import load_model
model_best = load_model('best_model_pretrain.hdf5',compile = False)

# Downloading images from internet using the URLs
!wget -O samosa.jpg http://veggiefoodrecipes.com/wp-content/uploads/2016/05/lentil-samosa-recipe-01.jpg
!wget -O pizza.jpg https://thumbs.dreamstime.com/b/supreme-pizza-446265.jpg

images = []
images.append('samosa.jpg')
images.append('pizza.jpg')
images.append('1818.jpg')
predict_class(model_best, images, True)

"""# **Model summary**"""

model.summary()

"""# **Applying SVM on feature extracted from resnet**"""

model.summary()

import cv2 
import keras 
model=keras.applications.ResNet50
model=keras.applications.ResNet50(weights='imagenet',input_shape=(224,224,3))
model = keras.models.Model(inputs = model.input, outputs = model.get_layer('res4f_branch2b').output)

classes = {'burger':0,'burrito':1,'club_sandwich':2,'donuts':3,'drink':4,'french_fries':5,'ice_cream':6,'pizza':7,'samosa':8}
ys=[]
for i in range(len(classes)):
    ys.append(i)

ys

import glob
valids=[]
for i in classes:
    valids.append(glob.glob("/content/Data/Valid/"+i+"/*"))
trains=[]
for i in classes:
    trains.append(glob.glob("/content/Data/Train/"+i+"/*"))

valid_image=[]
valid_y=[]
import numpy as np
cnt=0
cnt2=0
for i in valids:
    cnt2=0
    for j in i:
        # print(j)
        temp=(cv2.imread(j))
        temp=cv2.resize(temp,(224,224))
        temp=temp.reshape(1,224,224,3)
        valid_image.append(model.predict(temp).flatten())
        valid_y.append(cnt)
    cnt+=1

print(len(valid_y))
print(len(valid_image))

train_image=[]
train_y=[]
import numpy as np
cnt=0
cnt2=0
for i in trains:
    cnt2=0
    for j in i:
        # print(j)
        cnt2+=1
        temp=(cv2.imread(j))
        temp=cv2.resize(temp,(224,224))
        temp=temp.reshape(1,224,224,3)
        train_image.append(model.predict(temp).flatten())
        train_y.append(cnt)
    cnt+=1

print(len(train_y))
print(len(train_image))

from sklearn.preprocessing import MinMaxScaler
scaling = MinMaxScaler(feature_range=(-1,1)).fit(train_image)
X_train = scaling.transform(train_image)

from sklearn.svm import SVC
model1=SVC(kernel='linear',C=1,verbose=True)
model1.fit(X_train,train_y)

import pickle
with open('model1','wb') as f:
    pickle.dump(model1,f)

from sklearn.metrics import accuracy_score
valid_x=scaling.transform(valid_image) 
# acc=accuracy_score(valid_y, model1.predict(valid_x), normalize=False)
# from sklearn.model_selection import cross_val_score 
# scores = cross_val_score(model1, valid_x,valid_y, cv=5)

# print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
import numpy as np

"""# ***Accuracy using svm***"""

cnt_true=0
cnt_false=0
for i in range(len(valid_x)):
  temp=model1.predict(np.reshape(valid_x[i],(1,-1)))
  if temp== valid_y[i]:
    cnt_true+=1
  else:
    cnt_false+=1
acc=cnt_true/(cnt_true+cnt_false)
acc

from keras.utils import plot_model
import pydot
from IPython.display import SVG
from IPython.display import Image
from keras.utils.vis_utils import model_to_dot
plot_model(model, to_file='model.png')
#SVG(model_to_dot(model).create(prog='dot', format='svg'))
Image( filename='model.png')

"""# ***THANK YOU***"""